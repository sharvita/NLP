{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSCI 4580-5580: Data Science\n",
    "Lab 4: NLP Tools\n",
    "\n",
    "NOTE click near here to select this cell, esc-Enter will get you into cell edit mode, shift-Enter gets you back\n",
    "\n",
    "\n",
    "Name: Sharvita Paithankar\n",
    "\n",
    "Student ID: 108172438"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we'll explore NLP with the Stanford Parsing suite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE:\n",
    "The Stanford Parser requires the VM you set up in Lab 1. Please revisit that lab (specifically the prelab document) if you run into any issues regarding VM setup. Also this lab will be much easier if you have a shared folder setup for your VM. This was an optional step in the Lab 1 Prelab but it might be worth taking a couple minutes to revisit the document and setup a shared folder before starting this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Analysis of Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we're going to use a parser to extract some \"facts\" from natural language. The text is from the simplified wikipedia site: http://simple.wikipedia.org. It has been filtered to find sentences about cats. Download the <b>cat.txt</b> file from Canvas into your lab4 directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stanford Parser Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the Stanford parser from Canvas. If you have already downloaded it, you could use the shared folder to transfer it to Ubuntu.\n",
    "\n",
    "Unpack it with\n",
    "\n",
    "<pre>tar xvzf stanfordparser.tar.gz</pre>\n",
    "\n",
    "and then move it to the /opt directory with\n",
    "\n",
    "<pre>sudo mv StanfordParser /opt</pre>\n",
    "\n",
    "It will be helpful to have links to the parser scripts from your bin directory. **If you havent already, create a directory ~/bin and add it to your path with ```echo \"export PATH=~/bin:$PATH\" >> ~/.bashrc``` **\n",
    "Then\n",
    "<pre>\n",
    "cd ~/bin\n",
    "ln -s /opt/StanfordParser/lexparser.sh lexparser.sh\n",
    "ln -s /opt/StanfordParser/lexparser-gui.sh lexparser-gui.sh\n",
    "ln -s /opt/StanfordParser/dependencyviewer/dependencyviewer.sh dependencyviewer.sh\n",
    "</pre>\n",
    "\n",
    "These files will be in your path the next time you login. You can logout from the start button at the top right of the VM window. Then log back in again.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a terminal window, type\n",
    "\n",
    "<pre>lexparser-gui.sh</pre> \n",
    "or alternatively \n",
    "<pre>~/bin/lexparser-gui.sh</pre>\n",
    " **NOTE: if java is not already installed, you can install it with:**\n",
    "  <pre>sudo apt install default-jre</pre>\n",
    " \n",
    "\n",
    "This brings up a GUI interface to the Stanford parser. To use it, click on \"Load Parser\" which brings up a file selection dialog. Navigate to\n",
    "\n",
    "<pre>/opt/StanfordParser/stanford-parser-3.4.1-models.jar</pre>\n",
    "\n",
    "and open it.\n",
    "\n",
    "Then you will see a list of parsers to use. Select\n",
    "\n",
    "<pre>englishPCFG.ser.gz</pre>\n",
    "\n",
    "You're now ready to parse some text!\n",
    "\n",
    "Click on the \"Load File\" button, and browse to the lab4 directory and load the cat.txt file. Click on \"Parse\" to parse the current sentence (highlighted in yellow).\n",
    "\n",
    "### NOTE:\n",
    "The tags used by the parser are explained in more detail [here](https://gist.github.com/nlothian/9240750). The important parts of speech will be noun, verb, and subject. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Q1) Generate two parse tree visualizations for any pair of sentences from cat.txt. The tree should show up in the bottom panel of the Stanford Parser when you click Parse. Screenshot the trees and insert the images below ([see Stack Overflow post on adding image to Jupyter notebook](https://stackoverflow.com/questions/32370281/how-to-embed-image-or-picture-in-jupyter-notebook-either-from-a-local-machine-o)). Breifly reflect on the similarity/difference in structure between the two parse trees (for example: how are the parts of speech ordered, is one tree deeper/wider than the other, do the sentences seem like they should have similar/different trees but dont and why?) Make sure to submit the image files along with you notebook when you turn it in!\n",
    "\n",
    "\n",
    "\n",
    "![title](one.png)\n",
    "\n",
    "\n",
    "![title](two.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Q1 answer here\n",
    "\n",
    "how are the parts of speech ordered, is one tree deeper/wider than the other, do the sentences seem like they should have similar/different trees but dont and why?\n",
    "\n",
    "The first sentence is a very simple sentence hence the tree is smaller in height and width compared the the second tree, where the sentence is more complicated. The tress are perfectly ordered according to their sentences(meaning I can read the sentence when I go from right to left. The tress are a little different beacuse the first tree has less words and not \"LRB\" where as the second tree does. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing to XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll parse the cat sentence file to XML. To do this, we'll make a customized version of the parser script. Copy the file:\n",
    "\n",
    "<pre>/opt/StanfordParser/lexparser.sh</pre>\n",
    "\n",
    "and save it as:\n",
    "\n",
    "<pre>/opt/StanfordParser/parsetoxml.sh</pre>\n",
    "\n",
    "Edit it so that its outputFormat is:\n",
    "\n",
    "<pre>-outputFormat \"xmlTree\"</pre>\n",
    "\n",
    "and add a new option:\n",
    "\n",
    "<pre>-outputFormatOptions \"xml\"</pre>\n",
    "\n",
    "and create an alias to parsetoxml.sh it in your ~/bin directory.\n",
    "<pre>cd ~/bin</pre>\n",
    "<pre>ln -s /opt/StanfordParser/parsetoxml.sh parsetoxml.sh</pre>\n",
    "\n",
    "Now run from your lab4 directory\n",
    "\n",
    "<pre>parsetoxml.sh cat.txt > cat.xml</pre>\n",
    "\n",
    "you're ready now to analyze the cat data. We'll use Python's built-in ElementTree parser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with the XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now copy the cat.xml file out of the VM and into the same directory as this notebook (or a different directory if you prefer, **just be sure to change the path to the xml file below!**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "parser = etree.XMLParser(recover=True)\n",
    "tree = etree.parse('/Users/sharvitapaithankar/Desktop/Senior Year/Data Science/Lab 4/cat.xml',parser) # fix this path if you put the file somewhere else"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can examine the root of this tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'corpus'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root=tree.getroot()\n",
    "root.tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root[0].tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.e. we have found the first sentence. The xmlTree representation is a little tricky however, as POS tags are stored as attributes of nodes rather than node tags. To get to the actual root node, we need to dig a little deeper (and we'll use the second sentence which is a bit more conventional):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ROOT'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root[1][0][0].attrib['value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "going down one level gets us to the actual sentence node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=root[6][0][0][0]\n",
    "s.attrib['value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and to get its children we can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element node at 0x109d02e40>,\n",
       " <Element node at 0x109d02600>,\n",
       " <Element node at 0x109d02880>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not too helpful, because the node types are hidden in the value attributes of these nodes. To see them, we can use a python anonymous function and map it over the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NP', 'VP', '.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: x.attrib['value'], s[:]))\n",
    "# of if you prefer list comprehensions: nodes = [x.attrib['value'] for x in s[:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see if we can find sentences starting with noun phrases containing a given noun. The final function supports a flexible syntax (similar to xpath) for locating elements of given type or attributes. A slash \"/\" is like a directory specifier, and defines a child node. A double slash \"//\" specifies any descendent, child, grandchild, great-grandchild, etc. The \"node[@value='NP']\" specifies a node with the given attribute value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'value': 'cat'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = s.findall(\"./node[@value='NP']//node[@value='NN']//leaf[@value='cat']\")\n",
    "agent[0].attrib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finds all the nodes starting with an 'NP' child of s, and having a 'NN' node above a leaf with 'cat' value.\n",
    "\n",
    "We can similarly look for a verb in a verb phrase under the root node:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'value': 'is'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verb = s.findall(\"./node[@value='VP']//node[@value='VBZ']//leaf[@value='is']\")\n",
    "verb[0].attrib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting these together, we can discover sentences containing a given pair of (agent,action) pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printnode(node):\n",
    "    for i in node.findall(\".//leaf\"):\n",
    "        print(\" \" + i.attrib['value']),\n",
    "    print('')\n",
    "\n",
    "def testnode(node, agent, action):\n",
    "    aa = node.findall(\"./node[@value='NP']//node[@value='NN']//leaf[@value='\"+agent+\"']\")\n",
    "    bb = node.findall(\"./node[@value='VP']//leaf[@value='\"+action+\"']\")\n",
    "    if (len(aa) > 0 and len(bb) > 0):\n",
    "        printnode(node)    \n",
    "\n",
    "def agentact(node, agent, action):\n",
    "    testnode(node, agent, action)\n",
    "    snodes = node.findall(\".//node[@value='S']\")\n",
    "    for snode in snodes:\n",
    "        testnode(snode, agent, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A\n",
      " young\n",
      " cat\n",
      " is\n",
      " called\n",
      " a\n",
      " kitten\n",
      " .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "title = 'cat'\n",
    "agentact(s, title, 'is')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can apply the agentact function to all the sentences in the Wikipedia entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "[agentact(nn[0][0][0], title, 'is') for nn in root]\n",
    "[] # hide the return bvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Q2) Copy the code from the previous cell to the next cell and change the verb to something other than \"is\" that returns a few sentences. Can you find any sentences that share similar meaning based on their verb alone? Or completely different meaning? Write a breif sentence in a comment about what this could mean for an NLP model and the importance of having enough data.\n",
    "\n",
    "Answer :  The sentences share a similar meaning because the sentences describe what a cat can do. Since the sentences are all simplistic, the NLP model can pick up the sentences perfectly. When the sentences are a little bit complicated, you can see some of them do not make a lot of sense. \n",
    "\n",
    "> Q3) Finish the testnode2 function that returns sentences in which the given adjective (JJ) appears in the cell below, you will need to check for plural nouns (NNS) in addition to singular nouns, which requires a new search with a leaf node of \"cats\"instead of \"cat\". Try a few different adjectives (ex: wild, domestic, brown, etc.). Not all adjectives will return results, and you can always check the parse tree in the Stanford parser to check for available adjective-noun pairs. Do the sentences you see make sense? Now try the adjective \"dry\". Is cat/cats still the subject of the sentences you see returned, if not what is the subject of the sentence? Does this suggest anything to you about how the nuances of languages and how they should be modeled? Write 2-3 sentences in a comment about your observations. \n",
    "\n",
    "Answer : The sentences do make sense when the word \"cats\" is used. When the word \"brown\" is used, the sentences do not make sense. After using \"dry\", the sentences do not make sense but they are still on the topic of cats. Since the english language can have complicated sentences, the model does not work very well and hence does not serve its purpose. If used for simple sentences, this model can work great. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The\n",
      " cat\n",
      " creeps\n",
      " towards\n",
      " a\n",
      " chosen\n",
      " victim\n",
      " ,\n",
      " keeping\n",
      " its\n",
      " body\n",
      " flat\n",
      " and\n",
      " near\n",
      " to\n",
      " the\n",
      " ground\n",
      " so\n",
      " that\n",
      " it\n",
      " can\n",
      " not\n",
      " be\n",
      " seen\n",
      " easily\n",
      " ,\n",
      " until\n",
      " it\n",
      " is\n",
      " close\n",
      " enough\n",
      " for\n",
      " a\n",
      " rapid\n",
      " dash\n",
      " or\n",
      " pounce\n",
      " .\n",
      "\n",
      " The\n",
      " cat\n",
      " 's\n",
      " tongue\n",
      " can\n",
      " act\n",
      " as\n",
      " a\n",
      " hairbrush\n",
      " and\n",
      " can\n",
      " clean\n",
      " and\n",
      " untangle\n",
      " a\n",
      " cat\n",
      " 's\n",
      " fur\n",
      " .\n",
      "\n",
      " a\n",
      " cat\n",
      " gets\n",
      " fleas\n",
      " because\n",
      " fleas\n",
      " can\n",
      " make\n",
      " cats\n",
      " uncomfortable\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q2 code here\n",
    "[agentact(nn[0][0][0], title, 'can') for nn in root]\n",
    "[] # hide the return bvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " an\n",
      " entire\n",
      " male\n",
      " cat\n",
      " is\n",
      " a\n",
      " tom.Entire\n",
      " means\n",
      " a\n",
      " female\n",
      " cat\n",
      " that\n",
      " is\n",
      " not\n",
      " spayed\n",
      " ,\n",
      " and\n",
      " a\n",
      " male\n",
      " cat\n",
      " that\n",
      " is\n",
      " not\n",
      " neutered\n",
      " ,\n",
      " leaving\n",
      " either\n",
      " able\n",
      " to\n",
      " reproduce\n",
      "\n",
      " means\n",
      " a\n",
      " female\n",
      " cat\n",
      " that\n",
      " is\n",
      " not\n",
      " spayed\n",
      " ,\n",
      " and\n",
      " a\n",
      " male\n",
      " cat\n",
      " that\n",
      " is\n",
      " not\n",
      " neutered\n",
      " ,\n",
      " leaving\n",
      " either\n",
      " able\n",
      " to\n",
      " reproduce\n",
      "\n",
      " This\n",
      " helps\n",
      " to\n",
      " explain\n",
      " the\n",
      " cat\n",
      " 's\n",
      " spinal\n",
      " mobility\n",
      " and\n",
      " flexibility\n",
      " .\n",
      "\n",
      " to\n",
      " explain\n",
      " the\n",
      " cat\n",
      " 's\n",
      " spinal\n",
      " mobility\n",
      " and\n",
      " flexibility\n",
      "\n",
      " Behaviour\n",
      " thumb\n",
      " |\n",
      " right\n",
      " |\n",
      " 200px\n",
      " |\n",
      " The\n",
      " cat\n",
      " on\n",
      " the\n",
      " right\n",
      " is\n",
      " fed\n",
      " up\n",
      " with\n",
      " the\n",
      " cat\n",
      " on\n",
      " the\n",
      " left\n",
      "\n",
      " They\n",
      " are\n",
      " used\n",
      " between\n",
      " a\n",
      " mother\n",
      " cat\n",
      " and\n",
      " her\n",
      " kittens\n",
      " .\n",
      "\n",
      " This\n",
      " is\n",
      " because\n",
      " a\n",
      " male\n",
      " cat\n",
      " 's\n",
      " penis\n",
      " has\n",
      " a\n",
      " band\n",
      " of\n",
      " about\n",
      " 120-150\n",
      " backwards-pointing\n",
      " spines\n",
      " ,\n",
      " which\n",
      " are\n",
      " about\n",
      " one\n",
      " millimeter\n",
      " long\n",
      " ;\n",
      " upon\n",
      " withdrawal\n",
      " of\n",
      " the\n",
      " penis\n",
      " ,\n",
      " the\n",
      " spines\n",
      " rake\n",
      " the\n",
      " walls\n",
      " of\n",
      " the\n",
      " female\n",
      " 's\n",
      " vagina\n",
      " ,\n",
      " which\n",
      " is\n",
      " a\n",
      " triggerTrigger\n",
      " :\n",
      " in\n",
      " the\n",
      " sense\n",
      " of\n",
      " an\n",
      " event\n",
      " which\n",
      " starts\n",
      " other\n",
      " events\n",
      " .\n",
      "\n",
      " Your\n",
      " next\n",
      " job\n",
      " is\n",
      " to\n",
      " call\n",
      " the\n",
      " vet\n",
      " ,\n",
      " who\n",
      " will\n",
      " tell\n",
      " you\n",
      " when\n",
      " to\n",
      " bring\n",
      " the\n",
      " kits\n",
      " for\n",
      " their\n",
      " vaccination.How\n",
      " to\n",
      " look\n",
      " after\n",
      " your\n",
      " cat\n",
      "\n",
      " to\n",
      " call\n",
      " the\n",
      " vet\n",
      " ,\n",
      " who\n",
      " will\n",
      " tell\n",
      " you\n",
      " when\n",
      " to\n",
      " bring\n",
      " the\n",
      " kits\n",
      " for\n",
      " their\n",
      " vaccination.How\n",
      " to\n",
      " look\n",
      " after\n",
      " your\n",
      " cat\n",
      "\n",
      " will\n",
      " tell\n",
      " you\n",
      " when\n",
      " to\n",
      " bring\n",
      " the\n",
      " kits\n",
      " for\n",
      " their\n",
      " vaccination.How\n",
      " to\n",
      " look\n",
      " after\n",
      " your\n",
      " cat\n",
      "\n",
      " to\n",
      " bring\n",
      " the\n",
      " kits\n",
      " for\n",
      " their\n",
      " vaccination.How\n",
      " to\n",
      " look\n",
      " after\n",
      " your\n",
      " cat\n",
      "\n",
      " The\n",
      " cat\n",
      " 's\n",
      " tongue\n",
      " can\n",
      " act\n",
      " as\n",
      " a\n",
      " hairbrush\n",
      " and\n",
      " can\n",
      " clean\n",
      " and\n",
      " untangle\n",
      " a\n",
      " cat\n",
      " 's\n",
      " fur\n",
      " .\n",
      "\n",
      " Food\n",
      " thumb\n",
      " |\n",
      " left\n",
      " |\n",
      " 180px\n",
      " |\n",
      " A\n",
      " typical\n",
      " brown\n",
      " Burmese\n",
      " cat\n",
      " Many\n",
      " house\n",
      " cats\n",
      " eat\n",
      " food\n",
      " which\n",
      " their\n",
      " owners\n",
      " give\n",
      " them\n",
      " .\n",
      "\n",
      " |\n",
      " 180px\n",
      " |\n",
      " A\n",
      " typical\n",
      " brown\n",
      " Burmese\n",
      " cat\n",
      " Many\n",
      " house\n",
      " cats\n",
      " eat\n",
      " food\n",
      " which\n",
      " their\n",
      " owners\n",
      " give\n",
      " them\n",
      "\n",
      " There\n",
      " are\n",
      " many\n",
      " different\n",
      " types\n",
      " of\n",
      " cat\n",
      " food\n",
      " .\n",
      "\n",
      " There\n",
      " is\n",
      " moist\n",
      " canned\n",
      " food\n",
      " and\n",
      " also\n",
      " dry\n",
      " cat\n",
      " food\n",
      " which\n",
      " comes\n",
      " in\n",
      " different\n",
      " sized\n",
      " cans\n",
      " or\n",
      " bags\n",
      " and\n",
      " formulas\n",
      " .\n",
      "\n",
      " There\n",
      " are\n",
      " kitten\n",
      " formulas\n",
      " ,\n",
      " cat\n",
      " formulas\n",
      " ,\n",
      " health\n",
      " formulas\n",
      " ,\n",
      " formulas\n",
      " for\n",
      " reducing\n",
      " a\n",
      " cat\n",
      " 's\n",
      " weight\n",
      " ,\n",
      " and\n",
      " many\n",
      " others\n",
      " .\n",
      "\n",
      " reducing\n",
      " a\n",
      " cat\n",
      " 's\n",
      " weight\n",
      "\n",
      " Yet\n",
      " ,\n",
      " it\n",
      " 's\n",
      " best\n",
      " if\n",
      " the\n",
      " food\n",
      " is\n",
      " at\n",
      " least\n",
      " 95\n",
      " %\n",
      " meat\n",
      " ,\n",
      " as\n",
      " that\n",
      " 's\n",
      " a\n",
      " cat\n",
      " 's\n",
      " diet\n",
      " .\n",
      "\n",
      " the\n",
      " food\n",
      " is\n",
      " at\n",
      " least\n",
      " 95\n",
      " %\n",
      " meat\n",
      " ,\n",
      " as\n",
      " that\n",
      " 's\n",
      " a\n",
      " cat\n",
      " 's\n",
      " diet\n",
      "\n",
      " that\n",
      " 's\n",
      " a\n",
      " cat\n",
      " 's\n",
      " diet\n",
      "\n",
      " It\n",
      " is\n",
      " most\n",
      " important\n",
      " to\n",
      " get\n",
      " a\n",
      " young\n",
      " cat\n",
      " vaccinated\n",
      " against\n",
      " some\n",
      " of\n",
      " the\n",
      " most\n",
      " deadly\n",
      " diseases\n",
      " .\n",
      "\n",
      " to\n",
      " get\n",
      " a\n",
      " young\n",
      " cat\n",
      " vaccinated\n",
      " against\n",
      " some\n",
      " of\n",
      " the\n",
      " most\n",
      " deadly\n",
      " diseases\n",
      "\n",
      " Regular\n",
      " visits\n",
      " to\n",
      " a\n",
      " vet\n",
      " can\n",
      " keep\n",
      " a\n",
      " cat\n",
      " alive\n",
      " many\n",
      " extra\n",
      " years\n",
      " by\n",
      " catching\n",
      " sickness\n",
      " and\n",
      " disease\n",
      " early\n",
      " .\n",
      "\n",
      " Sometimes\n",
      " ,\n",
      " there\n",
      " is\n",
      " a\n",
      " mutation\n",
      " -LRB-\n",
      " change\n",
      " -RRB-\n",
      " in\n",
      " cat\n",
      " families\n",
      " .\n",
      "\n",
      " Look\n",
      " for\n",
      " titles\n",
      " like\n",
      " Encyclopedia\n",
      " of\n",
      " the\n",
      " cat\n",
      " ,\n",
      " or\n",
      " Cat\n",
      " encyclopedia\n",
      " .\n",
      "\n",
      " African\n",
      " Wildcat\n",
      " Calico\n",
      " cat\n",
      " List\n",
      " of\n",
      " cat\n",
      " breeds\n",
      " Other\n",
      " meanings\n",
      " of\n",
      " the\n",
      " word\n",
      " `\n",
      " cat\n",
      " '\n",
      " As\n",
      " a\n",
      " verb\n",
      " ,\n",
      " ``\n",
      " to\n",
      " cat\n",
      " ''\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def testnode2(node, agent, modifier):\n",
    "    # Q3 code here:\n",
    "\n",
    "    cc = node.findall(\"./node[@value='VP']//node[@value ='NP']//node[@value ='NP']//node[@value ='NN']//leaf[@value='\"+title+\"']\")\n",
    "    dd = node.findall(\"./node[@value='VP']//node[@value ='NP']//node[@value ='NP']//node[@value ='NN']//leaf[@value='\"+modifier+\"']\")\n",
    "    ee = node.findall(\"./node[@value='VP']//node[@value ='NP']//node[@value ='NP']//node[@value ='NN']//leaf[@value='\"+agent+\"']\")\n",
    "    if(len(cc) > 0 or len(dd) > 0) and len(ee) > 0:\n",
    "        printnode(node)\n",
    "    \n",
    "def agentact2(node, agent, modifier):\n",
    "    testnode2(node, agent, modifier)\n",
    "    snodes = node.findall(\".//node[@value='S']\")\n",
    "    for snode in snodes:\n",
    "        testnode2(snode, agent, modifier)\n",
    "        \n",
    "list(map(lambda nn: agentact2(nn[0][0][0], title, 'dry'), root))\n",
    "[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload your ipython notebook on Canvas under Lab4 on Thursday, 10/1/2020 by 11:59pm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
